{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect external weblinks fron NVD (national vulnerability database)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "save_dir = '/data/zhaohan/adv-reasoning/data/cyberkg-raw/nvd_cve_info/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "root = 'https://nvd.nist.gov/vuln/full-listing'\n",
    "response = requests.get(root)\n",
    "html = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "monthes = ['January', 'February', 'March', 'April', \n",
    "           'May', 'June', 'July', 'August', 'September', \n",
    "           'October', 'November', 'December']\n",
    "\n",
    "cve_urls = []\n",
    "for ele in tqdm(html.find_all('a'), desc='getting cve urls in NVD'):\n",
    "    if ele.text in monthes:\n",
    "        y_m_url = ele.get('href')  # link to year-month cve-id list, e.g. '/vuln/full-listing/2021/1'\n",
    "        y_m_url = os.path.join('https://nvd.nist.gov', y_m_url.strip('/'))\n",
    "        \n",
    "#         y_m_html = BeautifulSoup(requests.get(y_m_url).content, 'html.parser')\n",
    "        req = Request(y_m_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urlopen(req).read()\n",
    "        y_m_html = BeautifulSoup(webpage, 'html.parser')\n",
    "        for ele_2 in y_m_html.find_all('a'):\n",
    "            if 'CVE-' in ele_2.text \\\n",
    "            and ele_2.text.split('-')[1].isnumeric() \\\n",
    "            and ele_2.text.split('-')[2].isnumeric():\n",
    "                cve_urls.append(os.path.join('https://nvd.nist.gov', ele_2.get('href').strip('/')))\n",
    "    \n",
    "nvd_cve_info = defaultdict(dict)\n",
    "# {\n",
    "#     cve-id: 'nvd': <nvd webpage url> (str),\n",
    "#             'external': {\n",
    "#                 0: {\n",
    "#                     'url': <external webpage url> (str),\n",
    "#                     'types': [types of current resource]  list(str),\n",
    "#                 },\n",
    "#                 1: {\n",
    "#                     'url': <external webpage url> (str),\n",
    "#                     'types': [types of current resource]  list(str),\n",
    "#                 },\n",
    "#                 ...\n",
    "#             }\n",
    "# }\n",
    "counter = 0\n",
    "for cve_url in tqdm(cve_urls, desc='parsing cve-nvd webpages'):\n",
    "    assert cve_url.startswith('https://nvd.nist.gov/vuln/detail/CVE-')\n",
    "    cve_id = cve_url.split('/')[-1]\n",
    "    nvd_cve_info[cve_id]['nvd'] = cve_url\n",
    "    nvd_cve_info[cve_id]['external'] = defaultdict(dict)\n",
    "    \n",
    "    # cve_html = BeautifulSoup(requests.get(cve_url).content, 'html.parser')\n",
    "    req = Request(cve_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "    cve_html = BeautifulSoup(webpage, 'html.parser')\n",
    "    for tr in cve_html.find_all('tr'):\n",
    "        if tr.has_attr('data-testid') and tr.get('data-testid').startswith('vuln-hyperlinks-row'):\n",
    "            row_id = int(tr.get('data-testid').split('-')[-1]) \n",
    "\n",
    "            a = tr.find('a', attrs={'target': '_blank'}) # only one\n",
    "            if a.get('href') is not None: \n",
    "                nvd_cve_info[cve_id]['external'][row_id]['url'] = a.get('href') \n",
    "            else:\n",
    "                nvd_cve_info[cve_id]['external'][row_id]['url'] = ''\n",
    "            nvd_cve_info[cve_id]['external'][row_id]['types'] = []\n",
    "            for span in tr.find_all('span', attrs={'class': 'badge'}):\n",
    "                nvd_cve_info[cve_id]['external'][row_id]['types'].append(span.text)\n",
    "\n",
    "    if len(nvd_cve_info) > 2000:\n",
    "        with open(os.path.join(save_dir, '%d.json' % counter), 'w') as f:\n",
    "            json.dump(nvd_cve_info, f)\n",
    "            print('saved %s' % os.path.join(save_dir, '%d.json' % counter))\n",
    "        counter += 1\n",
    "        nvd_cve_info = defaultdict(dict)\n",
    "\n",
    "if len(nvd_cve_info) > 0:\n",
    "    with open(os.path.join(save_dir, '%d.json' % counter), 'w') as f:\n",
    "        json.dump(nvd_cve_info, f)\n",
    "        print('saved %s' % os.path.join(save_dir, '%d.json' % counter))\n",
    "        \n",
    "print('Done')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVE num: 150367, cumulative url num 611731, unique url num 361650\n",
      "\n",
      "All reported external link types: ['Patch', 'Mailing List', 'Product', 'Third Party Advisory', 'VDB Entry', 'Tool Signature', 'Mitigation', 'Broken Link', 'US Government Resource', 'Exploit', 'Not Applicable', 'Press/Media Coverage', 'Issue Tracking', 'Release Notes', 'Technical Description', 'Vendor Advisory', 'Permissions Required']\n",
      "\n",
      "1 www.securityfocus.com 60510\n",
      "2 exchange.xforce.ibmcloud.com 33381\n",
      "3 github.com 19952\n",
      "4 www.vupen.com 11667\n",
      "5 www.exploit-db.com 11218\n",
      "6 oval.cisecurity.org 10213\n",
      "7 www.securitytracker.com 9769\n",
      "8 www.openwall.com 6561\n",
      "9 bugzilla.redhat.com 6296\n",
      "10 securityreason.com 5233\n",
      "11 marc.info 5164\n",
      "12 securitytracker.com 4727\n",
      "13 lists.fedoraproject.org 4519\n",
      "14 packetstormsecurity.com 4496\n",
      "15 www.debian.org 4309\n",
      "16 lists.opensuse.org 4001\n",
      "17 tools.cisco.com 3988\n",
      "18 portal.msrc.microsoft.com 3885\n",
      "19 seclists.org 3501\n",
      "20 lists.apache.org 3228\n",
      "21 www.redhat.com 3138\n",
      "22 bugzilla.mozilla.org 3109\n",
      "23 www.kb.cert.org 3045\n",
      "24 www.zerodayinitiative.com 3022\n",
      "25 archives.neohapsis.com 2708\n",
      "26 www-01.ibm.com 2658\n",
      "27 access.redhat.com 2632\n",
      "28 rhn.redhat.com 2599\n",
      "29 www.ibm.com 2396\n",
      "30 code.google.com 2254\n",
      "31 www.ubuntu.com 2130\n",
      "32 www.mandriva.com 1970\n",
      "33 security.gentoo.org 1839\n",
      "34 jvn.jp 1831\n",
      "35 www.iss.net 1777\n",
      "36 git.kernel.org 1672\n",
      "37 sourceforge.net 1598\n",
      "38 usn.ubuntu.com 1452\n",
      "39 crbug.com 1355\n",
      "40 lists.debian.org 1343\n",
      "41 docs.microsoft.com 1315\n",
      "42 bugs.debian.org 1244\n",
      "43 www.mozilla.org 1185\n",
      "44 sunsolve.sun.com 1124\n",
      "45 packetstormsecurity.org 1121\n",
      "46 drupal.org 1039\n",
      "47 wordpress.org 987\n",
      "48 openwall.com 984\n",
      "49 jvndb.jvn.jp 967\n",
      "50 security.netapp.com 872\n"
     ]
    }
   ],
   "source": [
    "# analysis\n",
    "import os\n",
    "import json\n",
    "import validators\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "cve_exurl_dict = defaultdict(set)\n",
    "exurl_cve_dict = defaultdict(set)\n",
    "url_types_dict = defaultdict(set)\n",
    "for subdir, dirs, files in os.walk('./nvd_cve_info'):\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        with open(path) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            for cve_id, info in data.items():\n",
    "                if len(info['external']) > 0: \n",
    "                    for idx, url_info in info['external'].items():\n",
    "                        if validators.url(url_info['url']):\n",
    "                            cve_exurl_dict[cve_id].add(url_info['url'])\n",
    "                            exurl_cve_dict[url_info['url']].add(cve_id)\n",
    "                            url_types_dict[url_info['url']] |= set(url_info['types'])\n",
    "\n",
    "count = 0\n",
    "for k, v in cve_exurl_dict.items():\n",
    "    count += len(set(v))\n",
    "print('CVE num: %d, cumulative url num %d, unique url num %d\\n' \n",
    "      % (len(cve_exurl_dict), count, len(url_types_dict)))\n",
    "\n",
    "all_types = set()\n",
    "for url, types in url_types_dict.items():\n",
    "    all_types |= set(types)\n",
    "print('All reported external link types: %s\\n' % str(list(all_types)))\n",
    "\n",
    "# count sources of external urls\n",
    "domain_freq = {}\n",
    "for url in url_types_dict.keys():\n",
    "    if validators.url(url):\n",
    "        domain = url.split('/')[2]\n",
    "        if domain not in domain_freq:\n",
    "            domain_freq[domain] = 0\n",
    "        domain_freq[domain] += 1\n",
    "    \n",
    "topk_domain = []\n",
    "for i, k in enumerate(sorted(domain_freq.keys(), key=domain_freq.get, reverse=True)[:50]):\n",
    "    topk_domain.append(k)\n",
    "    print(i+1, k, domain_freq[k])\n",
    "    \n",
    "# source specific url analysis\n",
    "save_path = '/data/zhaohan/adv-reasoning/data/cyberkg-raw/cve_ex_links/'\n",
    "\n",
    "for i, domain in enumerate(topk_domain):\n",
    "    saved_info = {\n",
    "            'cve-ids': [],\n",
    "            'ex_url': [],\n",
    "            'types': [],\n",
    "        }\n",
    "    for url, types in url_types_dict.items():\n",
    "        if domain in url:\n",
    "            saved_info['cve-ids'].append(','.join(list(exurl_cve_dict[url])))            \n",
    "            saved_info['ex_url'].append(url)\n",
    "            saved_info['types'].append(','.join(list(types)))\n",
    "            \n",
    "    df = pd.DataFrame.from_dict(saved_info)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    df.to_csv(os.path.join(save_path, 'top%d.%s.%d.csv' % (i+1, domain, domain_freq[domain])), sep='|')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhaohan_conda_env",
   "language": "python",
   "name": "zhaohan_conda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
